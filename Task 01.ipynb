{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75b58f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"D:\\task 1\\customer_churn_dataset-training-master.csv\")\n",
    "\n",
    "# Drop CustomerID\n",
    "df.drop(\"CustomerID\", axis=1, inplace=True)\n",
    "\n",
    "# Drop the one row that has all NaNs\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Convert target to integer\n",
    "df[\"Churn\"] = df[\"Churn\"].astype(int)\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "df = pd.get_dummies(df, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4a96c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = df.drop(\"Churn\", axis=1)\n",
    "y = df[\"Churn\"]\n",
    "\n",
    "# Impute missing values if any\n",
    "imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Split into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optional: scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7d14f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:08:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train, y_train)\n",
    "y_pred_log = log_model.predict(X_val)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_val)\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a52c72ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ Logistic Regression\n",
      "âœ… Accuracy: 0.8964465162702598\n",
      "ðŸ“Š Confusion Matrix:\n",
      " [[34558  3505]\n",
      " [ 5625 44479]]\n",
      "ðŸ“‹ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88     38063\n",
      "           1       0.93      0.89      0.91     50104\n",
      "\n",
      "    accuracy                           0.90     88167\n",
      "   macro avg       0.89      0.90      0.90     88167\n",
      "weighted avg       0.90      0.90      0.90     88167\n",
      "\n",
      "ðŸ§  ROC-AUC Score: 0.8978246690280691\n",
      "\n",
      "ðŸ“Œ Random Forest\n",
      "âœ… Accuracy: 0.999625710299772\n",
      "ðŸ“Š Confusion Matrix:\n",
      " [[38061     2]\n",
      " [   31 50073]]\n",
      "ðŸ“‹ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     38063\n",
      "           1       1.00      1.00      1.00     50104\n",
      "\n",
      "    accuracy                           1.00     88167\n",
      "   macro avg       1.00      1.00      1.00     88167\n",
      "weighted avg       1.00      1.00      1.00     88167\n",
      "\n",
      "ðŸ§  ROC-AUC Score: 0.9996643712287229\n",
      "\n",
      "ðŸ“Œ XGBoost\n",
      "âœ… Accuracy: 0.9998412104302064\n",
      "ðŸ“Š Confusion Matrix:\n",
      " [[38062     1]\n",
      " [   13 50091]]\n",
      "ðŸ“‹ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     38063\n",
      "           1       1.00      1.00      1.00     50104\n",
      "\n",
      "    accuracy                           1.00     88167\n",
      "   macro avg       1.00      1.00      1.00     88167\n",
      "weighted avg       1.00      1.00      1.00     88167\n",
      "\n",
      "ðŸ§  ROC-AUC Score: 0.9998571337222968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "def evaluate_model(y_true, y_pred, name):\n",
    "    print(f\"\\nðŸ“Œ {name}\")\n",
    "    print(\"âœ… Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"ðŸ“Š Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"ðŸ“‹ Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(\"ðŸ§  ROC-AUC Score:\", roc_auc_score(y_true, y_pred))\n",
    "\n",
    "# ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª\n",
    "evaluate_model(y_val, y_pred_log, \"Logistic Regression\")\n",
    "evaluate_model(y_val, y_pred_rf, \"Random Forest\")\n",
    "evaluate_model(y_val, y_pred_xgb, \"XGBoost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e49c2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test Accuracy: 0.5012893404169385\n",
      "ðŸ“‹ Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.05      0.10     33881\n",
      "           1       0.49      1.00      0.65     30493\n",
      "\n",
      "    accuracy                           0.50     64374\n",
      "   macro avg       0.74      0.53      0.38     64374\n",
      "weighted avg       0.75      0.50      0.36     64374\n",
      "\n",
      "ðŸ§  ROC-AUC Score: 0.5261946233226413\n",
      "âœ… Predictions saved to: test_predictions_final.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "# âœ… Load training data (to get columns structure)\n",
    "train_df = pd.read_csv(r\"D:\\task 1\\customer_churn_dataset-training-master.csv\")\n",
    "for col in train_df.select_dtypes(include=\"object\").columns:\n",
    "    if col != \"Churn\":\n",
    "        train_df[col] = LabelEncoder().fit_transform(train_df[col].astype(str))\n",
    "train_processed = train_df.copy()\n",
    "\n",
    "# âœ… Load test data\n",
    "test_df = pd.read_csv(r\"D:\\task 1\\customer_churn_dataset-testing-master.csv\")\n",
    "ids = test_df[\"CustomerID\"]\n",
    "test_df.drop(\"CustomerID\", axis=1, inplace=True)\n",
    "\n",
    "# âœ… Encode categorical test data\n",
    "for col in test_df.select_dtypes(include=\"object\").columns:\n",
    "    if col != \"Churn\":\n",
    "        test_df[col] = LabelEncoder().fit_transform(test_df[col].astype(str))\n",
    "\n",
    "# âœ… Split test features and target (if exists)\n",
    "if \"Churn\" in test_df.columns:\n",
    "    y_test_true = test_df[\"Churn\"].astype(int)\n",
    "    X_test = test_df.drop(\"Churn\", axis=1)\n",
    "else:\n",
    "    y_test_true = None\n",
    "    X_test = test_df\n",
    "\n",
    "# âœ… Ensure test data has all train columns used in imputer\n",
    "train_cols = imputer.feature_names_in_\n",
    "for col in train_cols:\n",
    "    if col not in X_test.columns:\n",
    "        X_test[col] = 0\n",
    "\n",
    "X_test = X_test[train_cols]  # Reorder columns exactly\n",
    "\n",
    "# âœ… Apply same imputer and scaler from training\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# âœ… Predict using trained XGBoost model\n",
    "test_preds = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# âœ… Evaluate if true labels exist\n",
    "if y_test_true is not None:\n",
    "    print(\"âœ… Test Accuracy:\", accuracy_score(y_test_true, test_preds))\n",
    "    print(\"ðŸ“‹ Test Classification Report:\\n\", classification_report(y_test_true, test_preds))\n",
    "    print(\"ðŸ§  ROC-AUC Score:\", roc_auc_score(y_test_true, test_preds))\n",
    "\n",
    "# âœ… Save predictions\n",
    "output = pd.DataFrame({\"CustomerID\": ids, \"PredictedChurn\": test_preds})\n",
    "output.to_csv(\"test_predictions_final.csv\", index=False)\n",
    "print(\"âœ… Predictions saved to: test_predictions_final.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
